# Reinforcement Learning with GEM

In this document, we demonstrate how to integrate various LLM reinforcement learning (RL) frameworks with GEM to train your own agents. One of our key goals is to enable seamless integration with all major frameworks, allowing researchers to use their preferred tools while **easily comparing results across different setups**. We believe this level of interoperability is central to the mission of building a standardized suite of environments.

## Supported Training Frameworks

We currently support integration with the following RL frameworks:
- [x] [Oat](https://github.com/sail-sg/oat)
- [x] [Verl](https://github.com/volcengine/verl)
- [x] [OpenRLHF](https://github.com/OpenRLHF/OpenRLHF)
- [x] [RL2](https://github.com/ChenmienTan/RL2)
- [x] [Tinker](https://thinkingmachines.ai/tinker/) and [Tinker-Cookbook](https://github.com/thinking-machines-lab/tinker-cookbook)


## Getting Started
To get started, please refer to the detailed setup and usage instructions provided in each frameworkâ€™s corresponding folder. 